{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "HumanObservedFeaturesData = \"HumanObserved-Features-Data/HumanObserved-Features-Data.csv\"\n",
    "observedDiff = \"HumanObserved-Features-Data/diffn_pairs.csv\"\n",
    "observedSame = \"HumanObserved-Features-Data/same_pairs.csv\"\n",
    "\n",
    "TrainingPercent = 80\n",
    "ValidationPercent = 10\n",
    "TestPercent = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build dictionary (image_id --> attribute array)\n",
    "def buildDataDictionary():\n",
    "    with open(HumanObservedFeaturesData) as csv_File:\n",
    "        csv_reader = csv.reader(csv_File)\n",
    "        \n",
    "        #step over the column names\n",
    "        next(csv_reader)\n",
    "        \n",
    "        return {rows[1]:(rows[2], rows[3], rows[4], rows[5], rows[6], rows[7], rows[8], rows[9], rows[10]) for rows in csv_reader}\n",
    "\n",
    "    \n",
    "\n",
    "#returns tables of raw concatinated data  \n",
    "def buildRawConcatenationTables(dataDict):\n",
    "    diffMatrix = []\n",
    "    sameMatrix = []\n",
    "    #Build matrix for different writers\n",
    "    with open(observedDiff) as csv_diff:\n",
    "        diff_reader = csv.reader(csv_diff)\n",
    "        \n",
    "        #step over the column names\n",
    "        next(diff_reader)\n",
    "        \n",
    "        for row in diff_reader:\n",
    "            diffRow = []\n",
    "            diffRow.append(row[0])\n",
    "            diffRow.append(row[1])\n",
    "            for element in dataDict[row[0]]:\n",
    "                diffRow.append(element)\n",
    "            for element in dataDict[row[1]]:\n",
    "                diffRow.append(element)\n",
    "            diffMatrix.append(diffRow)\n",
    "     \n",
    "    #Build matrix for same writers\n",
    "    with open(observedSame) as csv_same:\n",
    "        same_reader = csv.reader(csv_same)\n",
    "        \n",
    "        #step over the column names\n",
    "        next(same_reader)\n",
    "        \n",
    "        for row in same_reader:\n",
    "            sameRow = []\n",
    "            sameRow.append(row[0])\n",
    "            sameRow.append(row[1])\n",
    "            for element in dataDict[row[0]]:\n",
    "                sameRow.append(element)\n",
    "            for element in dataDict[row[1]]:\n",
    "                sameRow.append(element)\n",
    "            sameMatrix.append(sameRow)\n",
    "            \n",
    "    return (diffMatrix, sameMatrix)\n",
    "    \n",
    "#Build Training Data: Parameter: tuple of different and same handwriters (diff, same)\n",
    "#Returns training matrix and target array in tuple (training matrix, target array) as numpy arrays\n",
    "def buildTrainingData(dataTuple):\n",
    "    diffMatrix = np.array(dataTuple[0])\n",
    "    sameMatrix = np.array(dataTuple[1])\n",
    "    trainingTarget = []\n",
    "    \n",
    "    T_lenSame = int(math.ceil(len(sameMatrix)*0.01*TrainingPercent))\n",
    "    T_lenDiff = int(math.ceil(len(diffMatrix)*0.01*TrainingPercent))\n",
    "    \n",
    "    #Create Target Array\n",
    "    for x in range(T_lenSame):\n",
    "        trainingTarget.append(1)\n",
    "    for x in range(T_lenDiff):\n",
    "        trainingTarget.append(0)\n",
    "        \n",
    "    trainingSame = sameMatrix[0:T_lenSame]\n",
    "    trainingDiff = diffMatrix[0:T_lenDiff]\n",
    "    \n",
    "    trainingMatrix = np.concatenate((trainingSame, trainingDiff))\n",
    "    \n",
    "    return (trainingMatrix, np.array(trainingTarget), (len(trainingDiff), len(trainingSame)))\n",
    "\n",
    "\n",
    "#build validation data: Parameters: different and same handwriters (diff, same), percent of val, # of training rows tuple (diff, same)\n",
    "#Returns validation matrix and target array in tuple (training matrix, target array) as numpy arrays\n",
    "def buildValData(rawDataTuple, ValPercent, TrainingDiffCount, TrainingSameCount):\n",
    "    diffMatrix = np.array(rawDataTuple[0])\n",
    "    sameMatrix = np.array(rawDataTuple[1])\n",
    "    valTarget = []\n",
    "    \n",
    "    valSizeSame = int(math.ceil(len(sameMatrix)*ValPercent*0.01))\n",
    "    valSizeDiff = int(math.ceil(len(diffMatrix)*ValPercent*0.01))\n",
    "    \n",
    "    #Create Target Array\n",
    "    for x in range(valSizeSame):\n",
    "        valTarget.append(1)\n",
    "    for x in range(valSizeDiff):\n",
    "        valTarget.append(0)\n",
    "    \n",
    "    valSame = sameMatrix[TrainingSameCount:(TrainingSameCount+valSizeSame)]\n",
    "    valDiff = diffMatrix[TrainingDiffCount:(TrainingDiffCount+valSizeDiff)]\n",
    "    \n",
    "    valMatrix = np.concatenate((valSame, valDiff))\n",
    "    \n",
    "    return (valMatrix, np.array(valTarget), (len(valDiff), len(valSame)))\n",
    "\n",
    "\n",
    "#def buildTestData():\n",
    "\n",
    "\n",
    "def buildTestData(rawDataTuple, ValDiffCount, ValSameCount, TrainingDiffCount, TrainingSameCount):\n",
    "    diffMatrix = np.array(rawDataTuple[0])\n",
    "    sameMatrix = np.array(rawDataTuple[1])\n",
    "    testTarget = []\n",
    "    \n",
    "    testSame = sameMatrix[(TrainingSameCount+ValSameCount):]\n",
    "    testDiff = diffMatrix[(TrainingDiffCount+ValDiffCount):]\n",
    "    \n",
    "    #Create Target Array\n",
    "    for x in range(len(testSame)):\n",
    "        testTarget.append(1)\n",
    "    for x in range(len(testDiff)):\n",
    "        testTarget.append(0)\n",
    "    \n",
    "    testMatrix = np.concatenate((testSame, testDiff))\n",
    "    \n",
    "    return (testMatrix, np.array(testTarget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dictionary of images and attributes\n",
    "dataDict = buildDataDictionary()\n",
    "\n",
    "#Get observed concatinated tables as tuple (different, same) \n",
    "observedRawConcatTables = buildRawConcatenationTables(dataDict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Concatenation\n",
      "\tTraining Matrix: (235059, 20)\n",
      "\tTarget Array: (235059,)\n"
     ]
    }
   ],
   "source": [
    "#build training data and return training matrix and target data\n",
    "\n",
    "#Observed Concatination Data\n",
    "observedTrainingConcatData = buildTrainingData(observedRawConcatTables)\n",
    "\n",
    "observedTrainingConcatMatrix = observedTrainingConcatData[0]\n",
    "observedTrainingConcatTarget = observedTrainingConcatData[1]\n",
    "\n",
    "observedTrainingConcatCounts = observedTrainingConcatData[2]\n",
    "\n",
    "print(\"Observed Concatenation\")\n",
    "print(\"\\tTraining Matrix: \" + str(observedTrainingConcatMatrix.shape))\n",
    "print(\"\\tTarget Array: \" + str(observedTrainingConcatTarget.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Concatenation\n",
      "\tValidation Matrix: (29384, 20)\n",
      "\tValidation Array: (29384,)\n"
     ]
    }
   ],
   "source": [
    "# Build Validation Data\n",
    "\n",
    "#Observed Concatination Data\n",
    "observedValConcatData = buildValData(observedRawConcatTables, ValidationPercent, observedTrainingConcatCounts[0], observedTrainingConcatCounts[1])\n",
    "\n",
    "observedValConcatMatrix = observedValConcatData[0]\n",
    "observedValConcatTarget = observedValConcatData[1]\n",
    "observedValConcatCounts = observedValConcatData[2]\n",
    "\n",
    "print(\"Observed Concatenation\")\n",
    "print(\"\\tValidation Matrix: \" + str(observedValConcatMatrix.shape))\n",
    "print(\"\\tValidation Array: \" + str(observedValConcatTarget.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Concatenation\n",
      "\tTest Matrix: (29380, 20)\n",
      "\tTest Array: (29380,)\n"
     ]
    }
   ],
   "source": [
    "#Build Testing Data\n",
    "\n",
    "observedTestConcatData = buildTestData(observedRawConcatTables, observedValConcatCounts[0], observedValConcatCounts[1],\n",
    "                                       observedTrainingConcatCounts[0], observedTrainingConcatCounts[1])\n",
    "\n",
    "observedTestConcatMatrix = observedTestConcatData[0]\n",
    "observedTestConcatTarget = observedTestConcatData[1]\n",
    "\n",
    "print(\"Observed Concatenation\")\n",
    "print(\"\\tTest Matrix: \" + str(observedTestConcatMatrix.shape))\n",
    "print(\"\\tTest Array: \" + str(observedTestConcatTarget.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
